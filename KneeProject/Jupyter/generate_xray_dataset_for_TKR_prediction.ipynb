{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for pre-processing x-ray images and generating knee joint dataset\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import random as rand\n",
    "#import pandas as pd\n",
    "import numpy as np\n",
    "#from PIL import Image\n",
    "#import dicom\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage as ndimage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to Preprocess Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods for preprocessing the images \n",
    "# Changes resolution, rescales pixel values, changes MONOCHROME1, crops approximate knee joint areas\n",
    "\n",
    "'''\n",
    "    Def:\n",
    "        Interpolate image to get a fixed resolution - we use a scaling factor of 0.2\n",
    "    Params:\n",
    "        image_dicom = dicom of xray images\n",
    "        scaling_factor = factor to scale resolution\n",
    "    Return:\n",
    "        image_array = array for image with scaled resolution\n",
    "'''\n",
    "def interpolate_resolution(image_dicom, scaling_factor):\n",
    "    \n",
    "    image_array = image_dicom.pixel_array\n",
    "    \n",
    "    x = image_dicom[0x28, 0x30].value[0]\n",
    "    y = image_dicom[0x28, 0x30].value[1]\n",
    "    \n",
    "    image_array = ndimage.zoom(image_array, [x/scaling_factor, y/scaling_factor])\n",
    "    return image_array\n",
    "\n",
    "\n",
    "'''\n",
    "    Def:\n",
    "        Function for re-scaling images that have (0028, 1050) and (0028, 1051) dicom headers\n",
    "        Re-scale the pixel values using \n",
    "        Method from ftp://dicom.nema.org/MEDICAL/dicom/2014c/output/chtml/part03/sect_C.11.2.html#sect_C.11.2.1.2)\n",
    "    Params:\n",
    "        image_dicom = dicom of xray images\n",
    "        image_array = array for an image\n",
    "    Return:\n",
    "        image_array = array for image that has pixel values rescaled using a different method\n",
    "'''\n",
    "def scale_pixel_values_using_cw(image_dicom, image_array):\n",
    "    \n",
    "    c = image_dicom[0x28, 0x1050].value\n",
    "    w = image_dicom[0x28, 0x1051].value\n",
    "    \n",
    "    image_array = np.where(image_array <= (c - 0.5 - (w-1)/2), 0,  \n",
    "                           np.where(image_array > c - 0.5 + (w-1)/2, 255.0, \n",
    "                                    np.float32(((image_array - (c-0.5))/(w-1) + 0.5) * 255.0 )))\n",
    "    return image_array\n",
    "\n",
    "\n",
    "'''\n",
    "    Def:\n",
    "        Function for re-scaling images that have type LOG_E REL for header (0028, 1054)\n",
    "    Params:\n",
    "        image_dicom = dicom of xray images\n",
    "        image_array = array for an image\n",
    "    Return:\n",
    "        image_array = array for image that has pixel values rescaled using a logerel method\n",
    "'''\n",
    "def scale_pixel_values_using_logerel(image_dicom, image_array):\n",
    "    \n",
    "    intercept = image_dicom[0x28, 0x1052].value\n",
    "    slope = image_dicom[0x28, 0x1053].value\n",
    "    \n",
    "    # For edge cases w/o intercept or slope values, then we will force the use of intercept = 0.0, slope = 1.0\n",
    "    if isinstance(intercept, str):\n",
    "        intercept = 0.0\n",
    "        slope = 1.0\n",
    "        print(image_dicom[0x10, 0x20].value + ' is an edge  case for pixel scaling')\n",
    "    \n",
    "    # Linear transformation of data w/ slope and intercept values\n",
    "    image_array = slope * image_array + intercept\n",
    "    \n",
    "    minimum = np.min(image_array)\n",
    "    maximum = np.max(image_array)\n",
    "    \n",
    "    # Re-scale to new range of 0-255\n",
    "    image_array = np.float32(255.0 * (image_array - minimum) / (maximum - minimum))\n",
    "    return image_array\n",
    "\n",
    "\n",
    "'''\n",
    "    Def:\n",
    "        Function for inverting images with MONOCHROME1 after the images have been converted to same pixel scale\n",
    "    Params:\n",
    "        image_array = array for an image\n",
    "    Return:\n",
    "        image_array = image with monochrome1 inverted\n",
    "'''\n",
    "def invert_Monochrome1(image_array):\n",
    "    image_array = -image_array + 255.0\n",
    "    return image_array\n",
    "\n",
    "\n",
    "'''\n",
    "    Def:\n",
    "        Method to automatically extract knee joint\n",
    "        For parameter side: 1 = right, 0 = left\n",
    "    Params:\n",
    "        image_array = array for an image\n",
    "        side = side of knee\n",
    "    Return:\n",
    "        image_array = cropped knee joint array\n",
    "'''\n",
    "def extract_knee(image_array, side):\n",
    "    \n",
    "    print('Dimensions of image: ', image_array.shape)\n",
    "    \n",
    "    # Compute the sum of each row and column\n",
    "    col_sums = np.sum(image_array, axis = 0)\n",
    "    row_sums = np.sum(image_array, axis = 1)\n",
    "    \n",
    "    # Row index for cropping is centered at the minimum of the row_sums array\n",
    "    row_start = np.argmin(row_sums)-512\n",
    "    row_end = np.argmin(row_sums)+512\n",
    "    print('Row Indices Original: ', row_start, row_end)\n",
    "    \n",
    "    # However, if either the start or end of the row values is beyond the original image array shape\n",
    "    # We center the cropped image at the center row of the original image array\n",
    "    if row_start < 0 or row_end > (image_array.shape[0]-1):\n",
    "            row_start = round(image_array.shape[0]/2)-512\n",
    "            row_end = round(image_array.shape[0]/2)+512\n",
    "            \n",
    "    print('Row Indices Final: ', row_start, row_end)\n",
    "    \n",
    "    # For right knee, crop columns to be centered at the maximum sum of the LHS of original image array \n",
    "    # Shift over by 500 columns in edge cases with white outer bars   \n",
    "    if side == 1:\n",
    "        col_center = 500+np.argmax(col_sums[500:round(col_sums.shape[0]/2)])\n",
    "        print('Column Indices for Right Original: ', col_center-512, col_center+512)\n",
    "        \n",
    "        # If column is below original image array size, then start cropping on left hand border and go out 1024 columns\n",
    "        if (col_center - 512) < 0:\n",
    "            print('Column Indices for Right Final: ', 0, 1024)\n",
    "            image_array = image_array[row_start:row_end, :1024]           \n",
    "            \n",
    "        else:\n",
    "            image_array = image_array[row_start:row_end, (col_center-512):(col_center+512)]\n",
    "            print('Column Indices for Right Final: ', col_center-512, col_center+512)\n",
    "            \n",
    "    # For left knee, crop columns to be centered at the maximum sum of the RHS of original image array \n",
    "    # Shift over by 500 columns in edge cases with white outer bars\n",
    "    if side == 0:\n",
    "        col_center = round(col_sums.shape[0]/2)+np.argmax(col_sums[round(col_sums.shape[0]/2):col_sums.shape[0]-500])\n",
    "        print('Column Indices for Left Original: ', col_center-512, col_center+512)\n",
    "       \n",
    "        # If column is above original image array size, then start cropping on right hand border and go in 1024 columns\n",
    "        if (col_center + 512) > (image_array.shape[1]-1):\n",
    "            print('Column Indices for Left Final: ', image_array.shape[1]-1024, image_array.shape[1]-1)\n",
    "            image_array = image_array[row_start:row_end, image_array.shape[1]-1024:]\n",
    "            \n",
    "        else:\n",
    "            image_array = image_array[row_start:row_end, (col_center-512):(col_center+512)]\n",
    "            print('Column Indices for Left Final: ', col_center-512, col_center+512)\n",
    "    return image_array\n",
    "\n",
    "\n",
    "'''\n",
    "    Def:\n",
    "        Take right or left side of image - does not crop 1024x1024 sized images but just slices the image into right / left halves\n",
    "        1 = right, 0 = left\n",
    "    Params:\n",
    "        image_array = array for an image\n",
    "        side = right or left\n",
    "    Returns:\n",
    "        image_array = cropped right / left side of knee xray\n",
    "'''\n",
    "def take_side(image_array, side):\n",
    "    \n",
    "    if side == 1:\n",
    "        image_array = image_array[:, :round(image_array.shape[1]/2)]\n",
    "        \n",
    "    if side == 0:\n",
    "        image_array = image_array[:, round(image_array.shape[1]/2):]\n",
    "        \n",
    "    return image_array\n",
    "\n",
    "\n",
    "'''\n",
    "    Def:\n",
    "        Method for pre-processing the images, which combines the above methods\n",
    "        1. Re-scale image depending on what DICOM header information is available\n",
    "        2. If image is MONOCHROME1 - invert to MONOCHROME2 scale\n",
    "        3. Interpolate image with a new pixel scaling factor of: (from DICOM) original-pixel-width / 0.2\n",
    "    Params:\n",
    "        image_dicom = dicom of image (information with image array)\n",
    "    Return:\n",
    "        image_array = preprocessed image\n",
    "'''\n",
    "def augment_xrays(image_dicom):\n",
    "    \n",
    "    image_array = interpolate_resolution(image_dicom, 0.2)\n",
    "    \n",
    "    if (0x28, 0x1050) in image_dicom and (0x28, 0x1051) in image_dicom:\n",
    "        image_array = scale_pixel_values_using_cw(image_dicom, image_array)\n",
    "        print('Scaled with 28, 1050 and 28, 1051 method')\n",
    "    \n",
    "    else: \n",
    "        image_array = scale_pixel_values_using_logerel(image_dicom, image_array)\n",
    "        print('Scaled with Linear Transform')\n",
    "        \n",
    "    if image_dicom[0x28, 0x04].value == \"MONOCHROME1\":\n",
    "        image_array = invert_Monochrome1(image_array)\n",
    "        print(image_dicom[0x10, 0x20].value, image_dicom[0x28, 0x04].value)\n",
    "        \n",
    "    return image_array \n",
    "\n",
    "\n",
    "'''\n",
    "    Def:\n",
    "        Writes the image to disk (from Cem)\n",
    "    Params:\n",
    "        img = the rgb image to save\n",
    "        path = the target path\n",
    "'''\n",
    "def save_image(img, path):\n",
    "    \n",
    "    Image.fromarray(img.round().astype(np.uint8)).save(path, 'jpeg', dpi=[300, 300], quality=90)\n",
    "\n",
    "\n",
    "'''\n",
    "    Def:\n",
    "        Converts the given array into a RGB image. If the number of channels is not\n",
    "        3 the array is tiled such that it has 3 channels\n",
    "    Params:\n",
    "        img = the array to convert [nx, ny, channels]\n",
    "    Return:\n",
    "        img = the rgb image [nx, ny, 3]\n",
    "'''\n",
    "def to_rgb(img):\n",
    "   \n",
    "    img = np.atleast_3d(img)\n",
    "    channels = img.shape[2]\n",
    "    if channels < 3:\n",
    "        img = np.tile(img, 3)\n",
    "    return img\n",
    "\n",
    "\n",
    "'''\n",
    "    Def:\n",
    "        Given a data frame of image id and side, preprocesses images (rescale, invert, interpolate, crop)\n",
    "        Other params denote which images we want (which visit (list of strings) and which cohort (a single string)) \n",
    "    Params:\n",
    "        data = list of IDs\n",
    "        months = list of months id\n",
    "        cohort = name of cohort\n",
    "    Return:\n",
    "        final_array_1024 = list with 2 arrays:\n",
    "                                1. patient information with id, label, side\n",
    "                                2. image pixels\n",
    "'''\n",
    "def fully_preprocess_xrays(data, months, cohort):\n",
    "    \n",
    "    # Create 2 Numpy arrays - one to encode patient information and the others to store the images (1024 and 224 scales)\n",
    "    # For array of patient information: \n",
    "    # 1st column = id, 2nd column = indicator for TKR (1) or no TKR (0), 3rd column = side - right (1) or left (0)\n",
    "    array_of_information = np.array(data.iloc[:,[1,6,7]])\n",
    "    array_of_images_1024 = np.empty([len(data), 1024, 1024], dtype=np.float32)\n",
    "    \n",
    "    # Iterate over the list of month codes\n",
    "    for j in months:\n",
    "        for i in range(len(data)):\n",
    "            # path where DICOM images are stored\n",
    "            path = 'R:\\\\denizlab\\\\denizlabspace\\\\Users\\\\Kevin_Leung\\\\2017-07-26 Kevin\\\\' + cohort + ' raw\\\\' + str(data.iloc[i,1]) + '\\\\xray\\\\' + j\n",
    "            print(i, path)\n",
    "            image_dicom = dicom.read_file(path)\n",
    "            \n",
    "            # Entire image preprocessing procedure\n",
    "            image_array = augment_xrays(image_dicom)\n",
    "            image_array_1024 = extract_knee(image_array, data.iloc[i,7])\n",
    "            print('Min and Max of Full Image:    ', np.min(image_array), np.max(image_array))\n",
    "            print('Min and Max of Cropped Image: ', np.min(image_array_1024), np.max(image_array_1024))\n",
    "            print()\n",
    "            \n",
    "            # Store the arrays in corresponding parent arrays\n",
    "            array_of_images_1024[i,:,:] = image_array_1024\n",
    "            \n",
    "            # Paths to save jpegs for images\n",
    "            preprocessed_image_file = str(data.iloc[i,1]) + '_label_' + str(data.iloc[i,6]) + '_side_' + str(data.iloc[i,7]) + '_month_' + j +'.jpeg'  \n",
    "            preprocessed_path_1024 = 'R:\\\\denizlab\\\\denizlabspace\\\\Users\\\\Kevin_Leung\\\\2017-07-26 Kevin\\\\' + cohort + ' preprocessed\\\\jpegs_of_preprocessed_knees_1024x1024\\\\' + preprocessed_image_file  \n",
    "            \n",
    "            # First convert to rgb for jpeg format then save in the above path\n",
    "            image_to_save_1024 = to_rgb(image_array_1024)\n",
    "            save_image(image_to_save_1024, preprocessed_path_1024)\n",
    "                    \n",
    "    # Final array to return combines the numpy array for patient information and the preprocessed image arrays                \n",
    "    final_array_1024 = [array_of_information, array_of_images_1024]\n",
    "    return final_array_1024  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods for randomly separating 1024x1024 images into train, validation, and test sets\n",
    "\n",
    "'''\n",
    "    Def:\n",
    "        Randomize original datasets\n",
    "    Params:\n",
    "        patient_info = array of patient information with id, label, side\n",
    "        images = array of images\n",
    "        dim_1 = size of first dimension\n",
    "        dim_2 = size of second dimension\n",
    "    Return:\n",
    "        randomized_patient_info = patient information array that is randomly scrambled\n",
    "        randomized_images = patient images that are randomly scrambled\n",
    "'''\n",
    "def randomized_data(patient_info, images, dim_1, dim_2):\n",
    "    \n",
    "    randomized_indices = rand.sample(range(728), 728)\n",
    "    randomized_patient_info = np.zeros([728,3])\n",
    "    randomized_images = np.zeros([728, dim_1, dim_2])\n",
    "    \n",
    "    for i in range(728):\n",
    "        randomized_patient_info[i] = patient_info[randomized_indices[i]]\n",
    "        randomized_images[i] = images[randomized_indices[i]]\n",
    "        \n",
    "    return randomized_patient_info, randomized_images\n",
    "\n",
    "\n",
    "'''\n",
    "    Def:\n",
    "        Separate data set into training, validation, and test sets\n",
    "        First randomly shuffle vector of 0-727 which will be used as the indices for our respective datasets\n",
    "    Params:\n",
    "        patient_info = array of patient information with id, label, side\n",
    "        images = array of images\n",
    "        dim_1 = size of first dimension\n",
    "        dim_2 = size of second dimension\n",
    "    Return:\n",
    "        training_data = training set after scrambled\n",
    "        validation_data = validation set after scrambled\n",
    "        test_data = test set after scrambled\n",
    "'''\n",
    "def separate_sets_v2(patient_info, images, dim_1, dim_2):\n",
    "    \n",
    "    randomized_patient_info, randomized_images = randomized_data(patient_info, images, dim_1, dim_2)\n",
    "    \n",
    "    training_patient_info = np.zeros([510, 3])\n",
    "    validation_patient_info = np.zeros([74, 3])\n",
    "    test_patient_info = np.zeros([144, 3])\n",
    "    \n",
    "    training_images = np.zeros([510, dim_1, dim_2])\n",
    "    validation_images = np.zeros([74, dim_1, dim_2])\n",
    "    test_images = np.zeros([144, dim_1, dim_2])\n",
    "    \n",
    "    j = 0\n",
    "    k = 0\n",
    "    l = 0\n",
    "\n",
    "    for i in range(728):\n",
    "        if randomized_patient_info[i,1] == 1:\n",
    "            if np.sum(training_patient_info[:,1]) < 255:\n",
    "                training_patient_info[j] = randomized_patient_info[i]\n",
    "                training_images[j] = randomized_images[i]\n",
    "                j += 1\n",
    "            \n",
    "            elif np.sum(validation_patient_info[:,1]) < 37:\n",
    "                validation_patient_info[k] = randomized_patient_info[i]\n",
    "                validation_images[k] = randomized_images[i] \n",
    "                k += 1\n",
    "            \n",
    "            elif np.sum(test_patient_info[:,1]) < 72:\n",
    "                test_patient_info[l] = randomized_patient_info[i]\n",
    "                test_images[l] = randomized_images[i]\n",
    "                l += 1\n",
    "                \n",
    "        elif randomized_patient_info[i,1] == 0:\n",
    "            if j - np.sum(training_patient_info[:,1]) < 255:\n",
    "                training_patient_info[j] = randomized_patient_info[i]\n",
    "                training_images[j] = randomized_images[i]\n",
    "                j += 1\n",
    "            \n",
    "            elif k - np.sum(validation_patient_info[:,1]) < 37:\n",
    "                validation_patient_info[k] = randomized_patient_info[i]\n",
    "                validation_images[k] = randomized_images[i] \n",
    "                k += 1\n",
    "            \n",
    "            elif l - np.sum(test_patient_info[:,1]) < 72:\n",
    "                test_patient_info[l] = randomized_patient_info[i]\n",
    "                test_images[l] = randomized_images[i]\n",
    "                l += 1\n",
    "                \n",
    "    training_data = [training_patient_info, training_images]\n",
    "    validation_data = [validation_patient_info, validation_images]\n",
    "    test_data = [test_patient_info, test_images]\n",
    "        \n",
    "    return training_data, validation_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Def:\n",
    "        Re-scale images to 224x224 from 1024x1024 in order to transfer learn from ResNet\n",
    "        Due to the interpolation, ranges can now be outside of 0-255, \n",
    "        so any negative values are pulled to 0 and anything over 255 is forced to 255 \n",
    "    Params:\n",
    "        all_images = array of all images\n",
    "        cohort = name of cohort\n",
    "        dim1 = size of dimension 1\n",
    "        dim2 = size of dimension 2\n",
    "        dim3 = size of dimension 3\n",
    "    Return:\n",
    "        final_array_224 = images resized to 224x224\n",
    "'''\n",
    "def rescale_to_224_original(all_images, cohort, dim1, dim2, dim3): \n",
    "    \n",
    "    array_of_images_224 = np.empty([all_images[1].shape[0],  dim1, dim2, dim3], dtype=np.float32)\n",
    "    \n",
    "    for i in range(all_images[1].shape[0]):\n",
    "        preprocessed_image_file = str(all_images[0][i,0]) + '_label_' + str(all_images[0][i,1]) + '_side_' + str(all_images[0][i,2]) + '_month_00' +'.jpeg'  \n",
    "        preprocessed_path_224 = 'R:\\\\denizlab\\\\denizlabspace\\\\Datasets\\\\OAI\\\\2017-07-26 Kevin\\\\' + cohort + ' preprocessed\\\\jpegs_of_preprocessed_knees_224x224\\\\' + preprocessed_image_file\n",
    "        \n",
    "        image_array_224 = ndimage.zoom(all_images[1][i,:,:], [dim1/1024.0, dim2/1024.0])\n",
    "        print(i, all_images[0][i,0], \"Original Range:\", np.min(image_array_224), np.max(image_array_224))\n",
    "        \n",
    "        image_array_224 = np.abs(np.where(image_array_224 < 0, 0.0,  \n",
    "                                          np.where(image_array_224 > 255.0, 255.0, image_array_224)))\n",
    "        print(i, all_images[0][i,0], \"Re-Scaled Range:\", np.min(image_array_224), np.max(image_array_224))\n",
    "        print()\n",
    "        \n",
    "        # Images are converted to have 3-color channels (done by just stacking the single array 3 times)\n",
    "        image_array_224 = to_rgb(image_array_224)\n",
    "        array_of_images_224[i] = image_array_224    \n",
    "        save_image(image_array_224, preprocessed_path_224)\n",
    "        \n",
    "    final_array_224 = [all_images[0], array_of_images_224]\n",
    "    return final_array_224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing X-Rays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydicom'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-339406bf7c3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/gpfs/data/denizlab/Users/bz1030/src/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpydicom\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdicom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pydicom'"
     ]
    }
   ],
   "source": [
    "sys.path.append('../')\n",
    "from src.utils import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_file_path='/gpfs/data/denizlab/Datasets/OAI_original/'\n",
    "month = '00m'\n",
    "method = 'mean',\n",
    "save_dir = '/gpfs/data/denizlab/Users/bz1030/test/test1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_file_path = os.path.join(content_file_path,month)\n",
    "file_name = 'contents.csv'\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
