6/21
ResNet 34 + ImageNet weight + Entorpy loss(beta = 0.1) + CE
Training for 7 epochs
############### Model Finished ####################
Confusion Matrix:
 [[1783  817  179   22    1]
 [ 310  579  270   67    1]
 [  86  256  971  336    4]
 [   5   14   57  727   65]
 [   0    0    4   21  207]]
Vanilla Accuracy:0.6291654379239162; Oulu Acc 0.6851
Test losses 1.4238149416369368; Test mse [0.5627]; Test acc [0.6291654379239162]; Test Kappa 0.8086;
Training took: 897.1893000602722 seconds

6/20

ResNet 34 + ImageNet wights + CBAM
2 epochs
Epoch 2: Train Loss (0.7739429858086346, 0.6727409198949168)
[[1147  116  146    2    0]
 [ 302  138  268    8    1]
 [  53   27  609   57    4]
 [   1    2   58  320   13]
 [   0    0    1   17   96]]
Epoch 2: Val Loss 0.7506751835275933; Val Acc 0.6943; Val MSE 0.5168; Val Kappa 0.8212;

Epoch 4
############### Model Finished ####################
Confusion Matrix:
 [[2315  263  219    5    0]
 [ 527  282  395   23    0]
 [ 125  149 1147  232    0]
 [   4    1   82  753   28]
 [   6    0    5   29  192]]
Oulu Acc 0.689
Test losses 0.7396732236198573; Test mse [0.4975]; Test acc [0.689]; Test Kappa 0.8344;

model_torch - store all model wrote by torch
    model_flatten_linear_layer - since the image size changed, this file handle this issue by changing linear layer to larger one.



Experiments:

5/20 ResNet34 with changed linear layer
Test losses 1.7898125279694796; Test mse [0.7785]; Test acc [0.5648]; Test Kappa 0.7545;
Training took: 967.7842710018158 seconds
This file has been discarded because the fully connected layer is wrong.


5/27
############### Model Finished ####################
[[50  0 37  0  0]
 [13  0 16  0  0]
 [21  0 23  0  0]
 [11  0 22  0  0]
 [ 3  0  4  0  0]]
73.0 200
0.2195
Test losses 1.427018610239029; Test mse [2.23]; Test acc [0.365]; Test Kappa 0.1492;
Training took: 33.30069303512573 seconds

Job number 1
'''
net = resnet34(pretrained=True)
        net.avgpool = nn.AvgPool2d(28,28)
        net.fc = nn.Linear(512,5)
        net = net.to(device)
        optimizer = optim.Adam(net.parameters(), lr=0.001,weight_decay=1e-4)
'''

